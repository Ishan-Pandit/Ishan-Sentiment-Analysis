{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <b> Sentiment Analysis of a WhatsApp Chat </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing required libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function which checks if the date and time format of the message is valid:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_datetime(s):\n",
    "\n",
    "    #pattern of data and time which will be used in the txt file\n",
    "    pattern = '^([0-9]+)(\\/)([0-9]+)(\\/)([0-9]+), ([0-9]+):([0-9]+)[ ]?(AM|PM|am|pm)? -'\n",
    "\n",
    "    #checking if the given format matches our standard format\n",
    "    result = re.match(pattern, s)\n",
    "    \n",
    "    if result:\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_contact(s):\n",
    "\n",
    "    s = s.split(\":\")\n",
    "    \n",
    "    if len(s)==2:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finding messages, using our defined functions to pre-process them correctly and returning the important information:\n",
    "\n",
    "1. Date when message was sent\n",
    "2. Time at which message was sent\n",
    "3. Person who sent that message\n",
    "4. Contents of the message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data_from_line(line):\n",
    "\n",
    "    #splitting line and storing it in new variable splitline\n",
    "    splitline = line.split(' - ')\n",
    "\n",
    "    dateTime = splitline[0] #extracting first element which is date-time\n",
    "    date, time = dateTime.split(\", \") #seperating date and time\n",
    "\n",
    "    #joining elements from the list starting from the second element, thus reconstructing the message part of the original string\n",
    "    message = \" \".join(splitline[1:]) \n",
    "\n",
    "    if check_contact(message):\n",
    "\n",
    "        #if a contact is found, splits the message into contact and message content, and stores it\n",
    "        splitmessage = message.split(\": \")\n",
    "        contact = splitmessage[0]\n",
    "        message = \" \".join(splitmessage[1:])\n",
    "    else:\n",
    "        contact = None\n",
    "    \n",
    "    return date, time, contact, message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Obtaining the data from the conversation and pre-processing it as required:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "conversation = r\"C:\\Users\\DELL\\Downloads\\WhatsApp Chat with Amit Sir Eng Coll.txt\"\n",
    "\n",
    "with open(conversation, encoding=\"utf-8\") as fp:\n",
    "    fp.readline()\n",
    "\n",
    "    messageBuffer = []\n",
    "    date, time, contact = None, None, None\n",
    "\n",
    "    while True:\n",
    "        line = fp.readline()\n",
    "\n",
    "        if not line:\n",
    "            break\n",
    "\n",
    "        line = line.strip() #removing leading and trailing white spaces to avoid issues\n",
    "\n",
    "        if check_datetime(line): #checking if the line contains a date-time stamp using our previously defined function\n",
    "\n",
    "            if len(messageBuffer) > 0:\n",
    "                data.append([date, time, contact, ' '.join(messageBuffer)])\n",
    "\n",
    "            messageBuffer.clear()\n",
    "            date, time, contact, message = extract_data_from_line(line)\n",
    "            messageBuffer.append(message)\n",
    "        \n",
    "        else:\n",
    "            messageBuffer.append(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Applying the sentiment intensity analyzer from the nltk package on each message of the conversation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date   Time            Contact  \\\n",
      "1  2021-02-22  19:52  Amit Sir Eng Coll   \n",
      "2  2021-02-22  19:52       Ishan Pandit   \n",
      "3  2021-02-22  19:55       Ishan Pandit   \n",
      "4  2021-02-22  19:55  Amit Sir Eng Coll   \n",
      "5  2021-02-22  19:55       Ishan Pandit   \n",
      "6  2021-02-22  19:56  Amit Sir Eng Coll   \n",
      "7  2021-02-22  19:56       Ishan Pandit   \n",
      "8  2021-02-22  19:56       Ishan Pandit   \n",
      "9  2021-02-22  19:57  Amit Sir Eng Coll   \n",
      "10 2021-02-22  19:59       Ishan Pandit   \n",
      "\n",
      "                                              Message  Positive  Negative  \\\n",
      "1                                                 Yes     1.000     0.000   \n",
      "2   Matlab I would get full 4 marks for this right...     0.000     0.000   \n",
      "3                     So where have I gone wrong sir?     0.000     0.383   \n",
      "4   Standard diductions are there in writing skill...     0.000     0.000   \n",
      "5                                    Oh okay okay sir     0.655     0.000   \n",
      "6   Presentation, grammar, language all we be eval...     0.000     0.000   \n",
      "7                                             Yes sir     0.730     0.000   \n",
      "8   Also sir, in tomorrow's paper, comprehension w...     0.000     0.000   \n",
      "9   Q.1)A Prose Comprehension                    (...     0.103     0.084   \n",
      "10  Sir so where is the grammar? Other than spot t...     0.000     0.234   \n",
      "\n",
      "    Neutral  \n",
      "1     0.000  \n",
      "2     1.000  \n",
      "3     0.617  \n",
      "4     1.000  \n",
      "5     0.345  \n",
      "6     1.000  \n",
      "7     0.270  \n",
      "8     1.000  \n",
      "9     0.812  \n",
      "10    0.766  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_32808\\742455082.py:3: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['Date'] = pd.to_datetime(df['Date'])\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#converting data into a pandas dataframe to ease handling of data\n",
    "df = pd.DataFrame(data, columns=[\"Date\", 'Time', 'Contact', 'Message'])\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "#removing rows with missing values\n",
    "data = df.dropna()\n",
    "\n",
    "#removing rows wherever media was present and was omitted\n",
    "data = data[data['Message'] != \"<Media omitted>\"]\n",
    "\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "sentiments = SentimentIntensityAnalyzer()\n",
    "\n",
    "#using polarity_scores function from the SentimentIntensityAnalyzer to obtain positive, negative and neutral scores\n",
    "data.loc[:, \"Positive\"] = data[\"Message\"].apply(lambda x: sentiments.polarity_scores(x)[\"pos\"])\n",
    "data.loc[:, \"Negative\"] = data[\"Message\"].apply(lambda x: sentiments.polarity_scores(x)[\"neg\"])\n",
    "data.loc[:, \"Neutral\"] = data[\"Message\"].apply(lambda x: sentiments.polarity_scores(x)[\"neu\"])\n",
    "\n",
    "print(data.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summing up the scores for each message, calculating which score turns out to be the highest, and displaying the corresponding result!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive score is:  6.944999999999999\n",
      "Negative score is:  3.0539999999999994\n",
      "Neutral score is:  32.0\n",
      "\n",
      "Your chat is predominantly neutral üòê \n"
     ]
    }
   ],
   "source": [
    "x = sum(data[\"Positive\"])\n",
    "y = sum(data[\"Negative\"])\n",
    "z = sum(data[\"Neutral\"])\n",
    "\n",
    "print(\"Positive score is: \", x)\n",
    "print(\"Negative score is: \", y)\n",
    "print(\"Neutral score is: \", z)\n",
    "\n",
    "def sentiment(a, b, c):\n",
    "    if (a>b) and (a>c):\n",
    "        print(\"\\nYour chat is predominantly positive üòä \")\n",
    "    elif (b>a) and (b>c):\n",
    "        print(\"\\nYour chat is predominantly negative ‚òπÔ∏è \")\n",
    "    else:\n",
    "        print(\"\\nYour chat is predominantly neutral üòê \")\n",
    "sentiment(x, y, z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thus, we used the Sentiment Intensity Analyzer from the nltk (Natural Language Tool Kit) to check what was the predominant emotion/sentiment present in any given WhatsApp chat."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can copy paste the path to the txt file of any WhatsApp chat of our liking and run the program to check the major sentiment present in the chat!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
